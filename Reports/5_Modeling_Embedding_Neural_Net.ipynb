{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TOp5r9EJwk4p"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xRUmcyvCJsem",
    "outputId": "1743d525-843b-4872-81e6-3257f2807bed"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m      3\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/gdrive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/gdrive/My Drive/Colab Notebooks/Multi_Label_Text_Classification\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "sys.path.append('/content/gdrive/My Drive/Colab Notebooks/Multi_Label_Text_Classification')\n",
    "base_dir = 'gdrive/My Drive/Colab Notebooks/Multi_Label_Text_Classification/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "izPpn887fH5Q"
   },
   "outputs": [],
   "source": [
    "!pip3 install --quiet \"tensorflow>=1.7\"\n",
    "!pip3 install --quiet tensorflow-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-12T19:02:17.597554Z",
     "start_time": "2019-03-12T19:01:56.079763Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "pr_bmQWWaG9C",
    "outputId": "f4043085-e0ed-41e4-c307-44c8e47275df",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ignore  the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import glob\n",
    "import functools \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "import re\n",
    "import os.path\n",
    "import math\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "#from sklearn.cross_validation import KFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy import sparse\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#from skmultilearn.problem_transform import LabelPowerset\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import scipy\n",
    "\n",
    "import nltk\n",
    "from wordcloud import WordCloud\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import unicodedata\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"talk\", font_scale=0.8)\n",
    "\n",
    "from helper_functions import *\n",
    "rdm_seed = 29\n",
    "np.random.seed(rdm_seed)\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.models import load_model\n",
    "import keras.optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gMMMuhxHaG9j"
   },
   "source": [
    "# MODELING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4FmtyD9RgXRO"
   },
   "source": [
    "**Loading the input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-12T19:02:23.465051Z",
     "start_time": "2019-03-12T19:02:17.601558Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "5OwlamR5aG9l"
   },
   "outputs": [],
   "source": [
    "#mydata_train = pd.read_csv('./../Data/preprocessed/movies_genres_train_preprocessed.csv')\n",
    "#mydata_test = pd.read_csv('./../Data/preprocessed/movies_genres_test_preprocessed.csv')\n",
    "#mydata = pd.read_csv('../Data/movies_genres.csv', delimiter='\\t')\n",
    "\n",
    "mydata_train = pd.read_csv(base_dir+'Data/preprocessed/movies_genres_train_preprocessed.csv')\n",
    "mydata_test = pd.read_csv(base_dir+'Data/preprocessed/movies_genres_test_preprocessed.csv')\n",
    "mydata = pd.read_csv(base_dir+'Data/movies_genres.csv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QgC2z4bxaG9t"
   },
   "outputs": [],
   "source": [
    "train_X, train_y = mydata_train['plot'], mydata_train.drop(['title', 'plot', 'plot_lang'], axis=1)\n",
    "test_X, test_y = mydata_test['plot'], mydata_test.drop(['title', 'plot', 'plot_lang'], axis=1)\n",
    "\n",
    "category_columns = train_y.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X5f4Bz2uaG-F"
   },
   "outputs": [],
   "source": [
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"\n",
    "embed = hub.Module(module_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7zFCTARoBEUT"
   },
   "source": [
    "## Obtain Plot Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qA10A8tABC1l"
   },
   "outputs": [],
   "source": [
    "# embed_movie_plots(train_X, train_or_test='train')\n",
    "# embed_movie_plots(test_X, train_or_test='test')\n",
    "\n",
    "train_files = glob.glob(base_dir+\"Data/preprocessed/embed_vector/*train*.npy\")\n",
    "train_vector_set = []\n",
    "for file in train_files:\n",
    "  train_vector_set.append(np.load(file))\n",
    "train_vector = np.concatenate(train_vector_set)\n",
    "\n",
    "test_files = glob.glob(base_dir+\"Data/preprocessed/embed_vector/*test*.npy\")\n",
    "test_vector_set = []\n",
    "for file in test_files:\n",
    "    test_vector_set.append(np.load(file))\n",
    "test_vector = np.concatenate(test_vector_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bl9BTeBi_ppk"
   },
   "source": [
    "## LabelPowerset\n",
    "We use a Neural Network model to make prediction among one of the 1505 unique genre combinations in our training data set. \n",
    "* Input Layer consists of 512 features\n",
    "* Output Layer consists of 1505 nodes representing the each of the unique genre combinations  \n",
    "  * We use softmax activation function since the classifier has to output one among the 1505 combinations\n",
    "* Hidden Layers - number of nodes in the hidden layer has to be in between the number of input and output nodes for optimal performance. We select 1024 neurons\n",
    "* Dropout of 20%. To avoid overfit, we randomly drop out 20% of the neurons in the hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CSGCCgFIllbn"
   },
   "outputs": [],
   "source": [
    "# Creating a LUT for the 1505 labels\n",
    "train_y_labels= train_y.groupby(list(category_columns)).ngroup()\n",
    "y_labels_lut = train_y.copy(deep=True) \n",
    "y_labels_lut['Labels'] = train_y_labels\n",
    "y_labels_lut = y_labels_lut.drop_duplicates()\n",
    "y_labels_lut = y_labels_lut.reset_index(drop=True).set_index('Labels').sort_index()\n",
    "\n",
    "\n",
    "# One-hot encoding the output labels\n",
    "num_classes = y_labels_lut.shape[0]\n",
    "train_y_onehot = np_utils.to_categorical(train_y_labels, num_classes = num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7i9Ek6BljmP2"
   },
   "outputs": [],
   "source": [
    "def gen_model(optimizer):\n",
    "  model = Sequential()\n",
    "  model.add(Dense(1024, activation='relu', input_shape=(512,)))\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Dense(1505, activation='softmax'))\n",
    "  model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "  return model\n",
    "lr_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=2, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xdAgkkM63cX8"
   },
   "source": [
    "**Stochastic Gradient Descent Optimizer** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 901
    },
    "colab_type": "code",
    "id": "mTb6N-RRyRLH",
    "outputId": "99ac19e9-01bf-45d5-d66c-93b0d38a6e9e"
   },
   "outputs": [],
   "source": [
    "epochs, batch_size = 20, 128\n",
    "model = gen_model(keras.optimizers.SGD(lr=1))\n",
    "model.fit(train_vector, train_y_onehot,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_split=0.3,\n",
    "          callbacks=[lr_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "colab_type": "code",
    "id": "RCDXPSm81g1n",
    "outputId": "01b62137-f980-4043-ba4c-1e4c39757e9d"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_vector)\n",
    "y_pred_label = pd.DataFrame(np.argmax(y_pred, axis=1))\n",
    "predictions = pd.merge(y_pred_label, y_labels_lut, how='left', left_on=0, right_on='Labels')[category_columns]\n",
    "accuracy(test_y, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ccnUR5zH3nvs"
   },
   "source": [
    "**Adam Optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "colab_type": "code",
    "id": "5OGbBJRH3sWm",
    "outputId": "e262fbf0-f0d6-411a-d5ef-510f05aa4754"
   },
   "outputs": [],
   "source": [
    "epochs, batch_size = 20, 128\n",
    "model = gen_model(keras.optimizers.Adam(lr=0.001))\n",
    "model.fit(train_vector, train_y_onehot,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_split=0.3,\n",
    "          callbacks=[lr_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "colab_type": "code",
    "id": "B7RBqcxsxC0x",
    "outputId": "f8279ece-3142-4fdc-e3ec-91b9d03f2d43"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_vector)\n",
    "y_pred_label = pd.DataFrame(np.argmax(y_pred, axis=1))\n",
    "predictions = pd.merge(y_pred_label, y_labels_lut, how='left', left_on=0, right_on='Labels')[category_columns]\n",
    "accuracy(test_y, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3EAYp4Kt30A7"
   },
   "source": [
    "**RMSProp Optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "colab_type": "code",
    "id": "lTLjU08R4AQW",
    "outputId": "0ca0f4e4-8fac-456a-ad21-b7e525b25251"
   },
   "outputs": [],
   "source": [
    "epochs, batch_size = 20, 128\n",
    "model = gen_model(keras.optimizers.RMSprop(lr=0.001))\n",
    "model.fit(train_vector, train_y_onehot,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_split=0.3,\n",
    "          callbacks=[lr_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "colab_type": "code",
    "id": "E7ard7-m3Zuk",
    "outputId": "6b6e7b63-82d3-4e0b-bd24-b9f8f0fc39f3"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_vector)\n",
    "y_pred_label = pd.DataFrame(np.argmax(y_pred, axis=1))\n",
    "predictions = pd.merge(y_pred_label, y_labels_lut, how='left', left_on=0, right_on='Labels')[category_columns]\n",
    "accuracy(test_y, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UYs4930D4GH3"
   },
   "source": [
    "**Adagrad**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "colab_type": "code",
    "id": "u9IQXjT34amh",
    "outputId": "6b403241-56c5-4cf8-a855-b80894d89a3f"
   },
   "outputs": [],
   "source": [
    "epochs, batch_size = 20, 128\n",
    "model = gen_model(keras.optimizers.Adagrad(lr=0.01))\n",
    "model.fit(train_vector, train_y_onehot,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_split=0.3,\n",
    "          callbacks=[lr_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "colab_type": "code",
    "id": "Du7Q_rdo4i9n",
    "outputId": "67d26dcd-4e2f-41c6-adc6-0ee9738eab10"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_vector)\n",
    "y_pred_label = pd.DataFrame(np.argmax(y_pred, axis=1))\n",
    "predictions = pd.merge(y_pred_label, y_labels_lut, how='left', left_on=0, right_on='Labels')[category_columns]\n",
    "accuracy(test_y, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IkPN7fsX4le8"
   },
   "source": [
    "**Adadelta**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 833
    },
    "colab_type": "code",
    "id": "s71_8CW04pP-",
    "outputId": "48090c9c-aee9-4d7a-9398-abb10ef0a755"
   },
   "outputs": [],
   "source": [
    "epochs, batch_size = 20, 128\n",
    "model = gen_model(keras.optimizers.Adadelta(lr=1.0))\n",
    "model.fit(train_vector, train_y_onehot,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_split=0.3,\n",
    "          callbacks=[lr_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "colab_type": "code",
    "id": "7JtYj2QS4qcN",
    "outputId": "ec2421da-ce92-4f55-a4c5-4c45b0951a19"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_vector)\n",
    "y_pred_label = pd.DataFrame(np.argmax(y_pred, axis=1))\n",
    "predictions = pd.merge(y_pred_label, y_labels_lut, how='left', left_on=0, right_on='Labels')[category_columns]\n",
    "accuracy(test_y, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gFFX2mfg77jG"
   },
   "source": [
    "**Observations/Conclusions**\n",
    "* Predictions using Sentence Embedding with Neural Networks doesnt really produce predictions as accurate as the simple ML models which used TF-IDF vectorizer\n",
    "* Adam Optimizer seems to perform best among the ones tried with a F1 score of 0.62"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jjhC10wSyRTv"
   },
   "source": [
    "## Binary Relevance\n",
    "Here we build an predictor for each genre separately. In other words, the output layer will have 28 nodes - each corresponding to a genre. We will use a threshold for each genre to make predictions whether the plot falls into that genre or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "colab_type": "code",
    "id": "d_IAp7yayRZt",
    "outputId": "f503c61f-b02d-4cb3-9bf6-0858a6471a08"
   },
   "outputs": [],
   "source": [
    "prob_thresh = (train_y.sum()/train_y.shape[0]).clip(upper=0.5)\n",
    "prob_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GkU3QtzKyRiR"
   },
   "outputs": [],
   "source": [
    "def gen_model_genre(optimizer):\n",
    "  model = Sequential()\n",
    "  model.add(Dense(800, activation='relu', input_shape=(512,)))\n",
    "  model.add(Dropout(0.25))\n",
    "  model.add(Dense(27, activation='sigmoid'))\n",
    "  model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "  return model\n",
    "lr_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=2, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "colab_type": "code",
    "id": "rcARuSaRySfd",
    "outputId": "e7c1228f-3df9-4312-ede1-d3bc58d707cc"
   },
   "outputs": [],
   "source": [
    "epochs, batch_size = 20, 128\n",
    "model = gen_model_genre(keras.optimizers.Adam(lr=0.001))\n",
    "model.fit(train_vector, train_y,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_split=0.3,\n",
    "          callbacks=[lr_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "colab_type": "code",
    "id": "DCm_JADTyStj",
    "outputId": "6e163841-7f2a-4913-e023-97012c57bac5"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_vector)\n",
    "predictions = pd.DataFrame(index=test_y.index, columns=test_y.columns)\n",
    "for i in range(y_pred.shape[0]):\n",
    "  predictions.iloc[i,:] = (y_pred[i,:]>prob_thresh).map({True:1, False:0})\n",
    "accuracy(test_y, predictions)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "5_Modeling_Embedding_Neural_Net.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
